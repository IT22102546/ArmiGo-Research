{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wrist Movement Classification with LSTM\n",
        "## Complete Training Pipeline - Generated from Google Colab\n",
        "## Generated on: 2026-01-11 08:30:56\n",
        "\n",
        "### Project Overview\n",
        "This notebook implements an LSTM-based deep learning model for classifying wrist movements using sensor data from IMU sensors.\n",
        "\n",
        "### Features:\n",
        "- Data preprocessing and feature engineering\n",
        "- LSTM sequence modeling\n",
        "- Model training with early stopping\n",
        "- Evaluation metrics and visualization\n",
        "- Model deployment and prediction functions\n",
        "\n",
        "### Requirements:\n",
        "- TensorFlow 2.x\n",
        "- scikit-learn\n",
        "- pandas, numpy\n",
        "- matplotlib, seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow scikit-learn pandas numpy matplotlib seaborn joblib -q\n",
        "\n",
        "print(\"✓ All required packages installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "import io\n",
        "import os\n",
        "import joblib\n",
        "import zipfile\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(\"\\n✓ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading utilities for Google Colab\n",
        "def upload_file_colab():\n",
        "    \"\"\"Upload and load CSV file in Google Colab\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            print(f'Uploaded file: {filename}')\n",
        "            return pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "    except ImportError:\n",
        "        print(\"Not in Google Colab environment\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading file: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_from_path(file_path):\n",
        "    \"\"\"Load CSV from local path\"\"\"\n",
        "    try:\n",
        "        return pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found at {file_path}\")\n",
        "        return None\n",
        "\n",
        "def load_from_content(content):\n",
        "    \"\"\"Load CSV from string content\"\"\"\n",
        "    try:\n",
        "        return pd.read_csv(io.StringIO(content))\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading from content: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✓ Data loading functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocess the dataset for wrist movement classification\"\"\"\n",
        "    data = df.copy()\n",
        "\n",
        "    # Display dataset info\n",
        "    print(f\"Dataset shape: {data.shape}\")\n",
        "    print(f\"Columns: {data.columns.tolist()}\")\n",
        "    print(f\"Movement types: {data['Movement'].unique()}\")\n",
        "    print(f\"Movement distribution:\\n{data['Movement'].value_counts()}\")\n",
        "\n",
        "    # Features to use\n",
        "    possible_features = [\n",
        "        'AccelX', 'AccelY', 'AccelZ',\n",
        "        'GyRIGHToX', 'GyRIGHToY', 'GyRIGHToZ',\n",
        "        'GyroX', 'GyroY', 'GyroZ',\n",
        "        'AngleX', 'AngleY', 'AngleZ',\n",
        "        'FlexionAngle', 'DeviationAngle'\n",
        "    ]\n",
        "\n",
        "    # Select only features that exist in the dataset\n",
        "    features = [col for col in possible_features if col in data.columns]\n",
        "\n",
        "    if not features:\n",
        "        # Use all numeric columns except label columns\n",
        "        exclude_cols = ['Timestamp', 'Gender', 'Age', 'Hand', 'Status', 'Movement']\n",
        "        features = [col for col in data.columns if col not in exclude_cols and data[col].dtype in [np.float64, np.int64]]\n",
        "\n",
        "    print(f\"\\nSelected features ({len(features)}): {features}\")\n",
        "\n",
        "    # Check for missing values\n",
        "    missing_values = data[features].isnull().sum().sum()\n",
        "    if missing_values > 0:\n",
        "        print(f\"Warning: {missing_values} missing values found in features\")\n",
        "        for col in features:\n",
        "            data[col] = data[col].fillna(data[col].mean())\n",
        "\n",
        "    # Extract features and labels\n",
        "    X = data[features].values\n",
        "    y = data['Movement'].values\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    print(f\"\\nClasses: {le.classes_}\")\n",
        "    print(f\"Class mapping: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
        "\n",
        "    return X, y_encoded, le, features\n",
        "\n",
        "print(\"✓ Preprocessing functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sequence Creation for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequences(X, y, sequence_length=50, step_size=25):\n",
        "    \"\"\"\n",
        "    Create sequences for LSTM\n",
        "    sequence_length: number of timesteps in each sequence\n",
        "    step_size: how many timesteps to move forward for next sequence\n",
        "    \"\"\"\n",
        "    X_sequences = []\n",
        "    y_sequences = []\n",
        "\n",
        "    for i in range(0, len(X) - sequence_length, step_size):\n",
        "        X_sequences.append(X[i:i + sequence_length])\n",
        "        # Use the majority label in the sequence\n",
        "        sequence_labels = y[i:i + sequence_length]\n",
        "        unique, counts = np.unique(sequence_labels, return_counts=True)\n",
        "        majority_label = unique[np.argmax(counts)]\n",
        "        y_sequences.append(majority_label)\n",
        "\n",
        "    return np.array(X_sequences), np.array(y_sequences)\n",
        "\n",
        "print(\"✓ Sequence creation function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. LSTM Model Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_lstm_model(input_shape, num_classes):\n",
        "    \"\"\"Build and compile simple LSTM model\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(32),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_advanced_lstm_model(input_shape, num_classes):\n",
        "    \"\"\"Build and compile advanced LSTM model with batch normalization\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.LSTM(32, return_sequences=True),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.LSTM(16),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"✓ LSTM model architectures defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training and validation metrics\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "    axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "    axes[0].set_title('Model Accuracy', fontsize=14)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "    axes[0].legend(fontsize=12)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Loss\n",
        "    axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "    axes[1].set_title('Model Loss', fontsize=14)\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Loss', fontsize=12)\n",
        "    axes[1].legend(fontsize=12)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    \"\"\"Plot confusion matrix\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names,\n",
        "                yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix - Test Set', fontsize=14)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate per-class metrics\n",
        "    print(\"\\nPer-class metrics:\")\n",
        "    print(\"-\" * 50)\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        precision = cm[i, i] / cm[:, i].sum() if cm[:, i].sum() > 0 else 0\n",
        "        recall = cm[i, i] / cm[i, :].sum() if cm[i, :].sum() > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        print(f\"{class_name:20s} Precision: {precision:.3f} | Recall: {recall:.3f} | F1-Score: {f1:.3f}\")\n",
        "\n",
        "print(\"✓ Visualization functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Main Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_wrist_movement_model(df=None, model_type='simple'):\n",
        "    \"\"\"\n",
        "    Main training pipeline for wrist movement classification\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"WRIST MOVEMENT CLASSIFICATION - LSTM MODEL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load data\n",
        "    if df is None:\n",
        "        print(\"\\nUpload your wrist movement dataset...\")\n",
        "        df = upload_file_colab()\n",
        "        if df is None:\n",
        "            print(\"No data loaded. Exiting...\")\n",
        "            return None\n",
        "\n",
        "    # 1. Preprocess data\n",
        "    print(\"\\n[1/7] Preprocessing data...\")\n",
        "    X, y_encoded, label_encoder, feature_names = preprocess_data(df)\n",
        "\n",
        "    # 2. Normalize features\n",
        "    print(\"\\n[2/7] Normalizing features...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # 3. Create sequences\n",
        "    print(\"\\n[3/7] Creating sequences for LSTM...\")\n",
        "    SEQUENCE_LENGTH = min(50, len(X_scaled) // 10)\n",
        "    STEP_SIZE = SEQUENCE_LENGTH // 2\n",
        "    X_sequences, y_sequences = create_sequences(X_scaled, y_encoded, SEQUENCE_LENGTH, STEP_SIZE)\n",
        "    print(f\"  Sequence shape: {X_sequences.shape}\")\n",
        "    print(f\"  Labels shape: {y_sequences.shape}\")\n",
        "\n",
        "    # 4. Split data\n",
        "    print(\"\\n[4/7] Splitting data...\")\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X_sequences, y_sequences, test_size=0.3, random_state=42, stratify=y_sequences\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        "    )\n",
        "    print(f\"  Train: {X_train.shape}\")\n",
        "    print(f\"  Validation: {X_val.shape}\")\n",
        "    print(f\"  Test: {X_test.shape}\")\n",
        "\n",
        "    # 5. Build model\n",
        "    print(\"\\n[5/7] Building LSTM model...\")\n",
        "    input_shape = (SEQUENCE_LENGTH, len(feature_names))\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    if model_type == 'simple':\n",
        "        model = build_lstm_model(input_shape, num_classes)\n",
        "    else:\n",
        "        model = build_advanced_lstm_model(input_shape, num_classes)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # 6. Train model\n",
        "    print(\"\\n[6/7] Training model...\")\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=0.00001,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=min(32, len(X_train)),\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 7. Evaluate model\n",
        "    print(\"\\n[7/7] Evaluating model...\")\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    # Visualizations\n",
        "    plot_training_history(history)\n",
        "    plot_confusion_matrix(y_test, y_pred, label_encoder.classes_)\n",
        "\n",
        "    # Save model\n",
        "    model.save('wrist_movement_model.keras')\n",
        "    joblib.dump(scaler, 'wrist_scaler.pkl')\n",
        "    joblib.dump(label_encoder, 'wrist_label_encoder.pkl')\n",
        "\n",
        "    print(\"\\n✓ Model saved as 'wrist_movement_model.keras'\")\n",
        "    print(\"✓ Scaler saved as 'wrist_scaler.pkl'\")\n",
        "    print(\"✓ Label encoder saved as 'wrist_label_encoder.pkl'\")\n",
        "\n",
        "    # Create prediction function\n",
        "    def predict_movement(new_data, sequence_length=SEQUENCE_LENGTH):\n",
        "        \"\"\"Predict movement for new data\"\"\"\n",
        "        if isinstance(new_data, np.ndarray):\n",
        "            if new_data.ndim == 1:\n",
        "                new_data = new_data.reshape(1, -1)\n",
        "            new_data = pd.DataFrame(new_data, columns=feature_names)\n",
        "\n",
        "        # Scale\n",
        "        X_new = scaler.transform(new_data[feature_names].values)\n",
        "\n",
        "        # Create sequence\n",
        "        if len(X_new) < sequence_length:\n",
        "            padding_needed = sequence_length - len(X_new)\n",
        "            X_new = np.pad(X_new, ((0, padding_needed), (0, 0)), 'edge')\n",
        "\n",
        "        sequence = X_new[:sequence_length].reshape(1, sequence_length, -1)\n",
        "        prediction_proba = model.predict(sequence, verbose=0)\n",
        "        prediction_idx = np.argmax(prediction_proba)\n",
        "        prediction_label = label_encoder.inverse_transform([prediction_idx])[0]\n",
        "        confidence = np.max(prediction_proba)\n",
        "\n",
        "        return {\n",
        "            'predicted_movement': prediction_label,\n",
        "            'confidence': confidence,\n",
        "            'probabilities': prediction_proba[0]\n",
        "        }\n",
        "\n",
        "    results = {\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'label_encoder': label_encoder,\n",
        "        'feature_names': feature_names,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'test_loss': test_loss,\n",
        "        'predict_function': predict_movement,\n",
        "        'sequence_length': SEQUENCE_LENGTH,\n",
        "        'class_names': label_encoder.classes_\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"✓ Main training pipeline defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def quick_test():\n",
        "    \"\"\"Create sample dataset for testing\"\"\"\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "    n_features = 11\n",
        "\n",
        "    sample_features = ['AccelX', 'AccelY', 'AccelZ',\n",
        "                      'GyRIGHToX', 'GyRIGHToY', 'GyRIGHToZ',\n",
        "                      'AngleX', 'AngleY', 'AngleZ',\n",
        "                      'FlexionAngle', 'DeviationAngle']\n",
        "\n",
        "    X = np.random.randn(n_samples, n_features)\n",
        "    movements = ['STEADY', 'FLEXION', 'EXTENSION', 'RADIAL_DEVIATION', 'ULNAR_DEVIATION']\n",
        "    y = np.random.choice(movements, n_samples)\n",
        "\n",
        "    df = pd.DataFrame(X, columns=sample_features)\n",
        "    df['Movement'] = y\n",
        "    df['Timestamp'] = np.arange(n_samples)\n",
        "    df['Gender'] = np.random.choice(['M', 'F'], n_samples)\n",
        "    df['Age'] = np.random.randint(10, 20, n_samples)\n",
        "    df['Hand'] = np.random.choice(['LEFT', 'RIGHT'], n_samples)\n",
        "    df['Status'] = 'H'\n",
        "\n",
        "    columns = ['Timestamp', 'Gender', 'Age', 'Hand', 'Status', 'Movement'] + sample_features\n",
        "    df = df[columns]\n",
        "\n",
        "    print(f\"Sample dataset created: {df.shape}\")\n",
        "    print(f\"Movement distribution:\\n{df['Movement'].value_counts()}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_trained_model(model_path='wrist_movement_model.keras',\n",
        "                      scaler_path='wrist_scaler.pkl',\n",
        "                      encoder_path='wrist_label_encoder.pkl'):\n",
        "    \"\"\"Load previously trained model\"\"\"\n",
        "    try:\n",
        "        model = keras.models.load_model(model_path)\n",
        "        scaler = joblib.load(scaler_path)\n",
        "        label_encoder = joblib.load(encoder_path)\n",
        "\n",
        "        print(\"✓ Model loaded successfully!\")\n",
        "        return model, scaler, label_encoder\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "print(\"✓ Utility functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Complete Usage Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Train with sample data\n",
        "print(\"Example 1: Training with sample data\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Uncomment to run:\n",
        "# sample_df = quick_test()\n",
        "# results = train_wrist_movement_model(df=sample_df, model_type='simple')\n",
        "\n",
        "# Example 2: Train with uploaded data\n",
        "print(\"\\nExample 2: Training with uploaded data\")\n",
        "print(\"-\" * 40)\n",
        "print(\"To train with your own data:\")\n",
        "print(\"1. Uncomment the code below\")\n",
        "print(\"2. Upload your CSV file when prompted\")\n",
        "print(\"3. Choose model type ('simple' or 'advanced')\")\n",
        "\n",
        "# Uncomment to run:\n",
        "# results = train_wrist_movement_model(model_type='simple')  # or 'advanced'\n",
        "\n",
        "# Example 3: Load and use trained model\n",
        "print(\"\\nExample 3: Loading trained model\")\n",
        "print(\"-\" * 40)\n",
        "print(\"To load and use a trained model:\")\n",
        "print(\"1. Make sure model files exist in the current directory\")\n",
        "print(\"2. Uncomment and run the code below\")\n",
        "\n",
        "# Uncomment to run:\n",
        "# model, scaler, label_encoder = load_trained_model()\n",
        "# if model is not None:\n",
        "#     print(\"Model loaded successfully!\")\n",
        "#     # Create sample data for prediction\n",
        "#     sample_data = np.random.randn(50, 11)  # 50 timesteps, 11 features\n",
        "#     print(f\"Sample data shape: {sample_data.shape}\")\n",
        "\n",
        "print(\"\\n✓ Usage examples ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Download Notebook and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a zip file with everything\n",
        "def create_complete_package():\n",
        "    \"\"\"Create a zip file with notebook and all related files\"\"\"\n",
        "    import zipfile\n",
        "    from datetime import datetime\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    zip_filename = f'wrist_movement_complete_{timestamp}.zip'\n",
        "    \n",
        "    # Files to include (if they exist)\n",
        "    files_to_include = []\n",
        "    \n",
        "    # Check for model files\n",
        "    model_files = [\n",
        "        'wrist_movement_model.keras',\n",
        "        'wrist_scaler.pkl',\n",
        "        'wrist_label_encoder.pkl'\n",
        "    ]\n",
        "    \n",
        "    for file in model_files:\n",
        "        if os.path.exists(file):\n",
        "            files_to_include.append(file)\n",
        "    \n",
        "    # Create the zip\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Add model files\n",
        "        for file in files_to_include:\n",
        "            zipf.write(file)\n",
        "            print(f\"✓ Added: {file}\")\n",
        "        \n",
        "        # Add notebook file (will be created below)\n",
        "        notebook_file = 'wrist_movement_notebook.ipynb'\n",
        "        zipf.write(notebook_file)\n",
        "        print(f\"✓ Added: {notebook_file}\")\n",
        "    \n",
        "    print(f\"\\n✓ Complete package created: {zip_filename}\")\n",
        "    return zip_filename\n",
        "\n",
        "# Download function\n",
        "def download_all_files():\n",
        "    \"\"\"Download all files including notebook and models\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        \n",
        "        print(\"Creating complete package...\")\n",
        "        zip_file = create_complete_package()\n",
        "        \n",
        "        print(\"\\nDownloading files...\")\n",
        "        files.download(zip_file)\n",
        "        \n",
        "        # Also offer individual downloads\n",
        "        print(\"\\nWould you like to download individual files?\")\n",
        "        print(\"1. Download just the notebook\")\n",
        "        print(\"2. Download model files\")\n",
        "        print(\"3. Skip individual downloads\")\n",
        "        \n",
        "        choice = input(\"Enter choice (1-3): \").strip()\n",
        "        \n",
        "        if choice == '1':\n",
        "            files.download('wrist_movement_notebook.ipynb')\n",
        "            print(\"✓ Notebook downloaded\")\n",
        "        elif choice == '2':\n",
        "            model_files = ['wrist_movement_model.keras', 'wrist_scaler.pkl', 'wrist_label_encoder.pkl']\n",
        "            for file in model_files:\n",
        "                if os.path.exists(file):\n",
        "                    files.download(file)\n",
        "                    print(f\"✓ Downloaded: {file}\")\n",
        "        else:\n",
        "            print(\"Skipping individual downloads\")\n",
        "            \n",
        "        print(\"\\n✓ All downloads complete!\")\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"Not in Google Colab. Files saved locally.\")\n",
        "        print(f\"Notebook: wrist_movement_notebook.ipynb\")\n",
        "        print(f\"Model: wrist_movement_model.keras (if exists)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading files: {e}\")\n",
        "\n",
        "print(\"✓ Download functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Main Execution Menu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main_menu():\n",
        "    \"\"\"Main menu for the wrist movement classification system\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"WRIST MOVEMENT CLASSIFICATION WITH LSTM\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nMAIN MENU:\")\n",
        "        print(\"1. Train model with uploaded data\")\n",
        "        print(\"2. Train model with sample data\")\n",
        "        print(\"3. Download complete notebook (.ipynb)\")\n",
        "        print(\"4. Download everything (notebook + models)\")\n",
        "        print(\"5. Exit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-5): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "            print(\"TRAINING WITH UPLOADED DATA\")\n",
        "            print(\"=\" * 70)\n",
        "\n",
        "            model_choice = input(\"\\nChoose model type (1 for simple, 2 for advanced): \").strip()\n",
        "            model_type = 'advanced' if model_choice == '2' else 'simple'\n",
        "\n",
        "            results = train_wrist_movement_model(model_type=model_type)\n",
        "            if results:\n",
        "                print(\"\\n✓ Training completed successfully!\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "            print(\"TRAINING WITH SAMPLE DATA\")\n",
        "            print(\"=\" * 70)\n",
        "\n",
        "            sample_df = quick_test()\n",
        "            model_choice = input(\"\\nChoose model type (1 for simple, 2 for advanced): \").strip()\n",
        "            model_type = 'advanced' if model_choice == '2' else 'simple'\n",
        "\n",
        "            results = train_wrist_movement_model(df=sample_df, model_type=model_type)\n",
        "            if results:\n",
        "                print(\"\\n✓ Sample training completed successfully!\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "            print(\"DOWNLOADING NOTEBOOK\")\n",
        "            print(\"=\" * 70)\n",
        "            \n",
        "            # First save the notebook\n",
        "            notebook_content = create_complete_colab_notebook()\n",
        "            notebook_file = 'wrist_movement_notebook.ipynb'\n",
        "            \n",
        "            with open(notebook_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(notebook_content, f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            print(f\"✓ Notebook saved as '{notebook_file}'\")\n",
        "            \n",
        "            # Download it\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                print(\"\\nDownloading notebook file...\")\n",
        "                files.download(notebook_file)\n",
        "                print(\"✓ Notebook downloaded successfully!\")\n",
        "            except ImportError:\n",
        "                print(f\"\\nNot in Colab. Notebook saved at: {notebook_file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading notebook: {e}\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "            print(\"DOWNLOADING COMPLETE PACKAGE\")\n",
        "            print(\"=\" * 70)\n",
        "            \n",
        "            # First save the notebook\n",
        "            notebook_content = create_complete_colab_notebook()\n",
        "            notebook_file = 'wrist_movement_notebook.ipynb'\n",
        "            \n",
        "            with open(notebook_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(notebook_content, f, indent=2, ensure_ascii=False)\n",
        "            \n",
        "            print(f\"✓ Notebook saved as '{notebook_file}'\")\n",
        "            \n",
        "            # Download everything\n",
        "            download_all_files()\n",
        "\n",
        "        elif choice == '5':\n",
        "            print(\"\\nExiting... Thank you for using Wrist Movement Classification!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"\\nInvalid choice. Please enter a number between 1 and 5.\")\n",
        "\n",
        "    print(\"\\nProgram terminated.\")\n",
        "\n",
        "# Run the main menu\n",
        "if __name__ == \"__main__\":\n",
        "    main_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Use This Notebook\n",
        "\n",
        "### Option 1: Run Everything at Once\n",
        "Run all cells above, then execute the cell below to start the interactive menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start the interactive menu\n",
        "print(\"Starting Wrist Movement Classification System...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Save the notebook first\n",
        "notebook_content = create_complete_colab_notebook()\n",
        "with open('wrist_movement_notebook.ipynb', 'w', encoding='utf-8') as f:\n",
        "    json.dump(notebook_content, f, indent=2, ensure_ascii=False)\n",
        "print(\"✓ Notebook saved as 'wrist_movement_notebook.ipynb'\")\n",
        "\n",
        "# Start the main menu\n",
        "main_menu()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "colab": {
      "name": "Wrist Movement Classification",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}